
This chapter extends the self-shielding correction methodology, validated for mono-isotopic samples in \autoref{chap:transmission-correction}, to multi-isotope systems. The underlying physical models for simulating resonance fluctuations are the same as in the mono-isotopic case, and the detailed characterization of the model's performance against parameters such as sample thickness, temperature, and external resonance pairs will not be repeated. Instead, this chapter focuses on the aspects unique to multi-isotope samples: the physics of inter-isotope dampening, the validation challenges that arise when multiple evaluations must be made mutually consistent, and the discovery and diagnosis of a variance-scaling artifact in the probability table methodology used by the MCNP benchmark.

The implementation of this capability also required a substantial modernization of the SAMMY codebase, which has yielded benefits well beyond the immediate goal. The refactored code integrates with the \texttt{fitAPI} interface and its associated fitting modules, enabling capabilities such as simultaneous fitting of multiple experimental datasets, energy-dependent parameter definitions, and propagation of experimental uncertainties into parameter covariances. The validation of this modernized, multi-isotope fitting workflow is a primary focus of this chapter.

\section{Motivation}
\label{sec:multi-iso-motivation}

The standard experimental approach for determining average resonance parameters in the URR has historically required measurements on at least two highly enriched samples of different thicknesses\cite{Bahran2015}. By varying the sample thickness, the sensitivity to self-shielding changes while the underlying resonance parameters remain constant, allowing the evaluator to disentangle the average cross section from the correction factor. This approach is effective but imposes a significant practical constraint: producing multiple thick, highly enriched samples is expensive, and for some isotopes it is prohibitively so\cite{Brown2023Zr}.

Extending the self-shielding correction to multi-isotope systems relaxes this constraint. If the average resonance parameters of the companion isotopes in a natural-element sample are already well characterized, a measurement on a single natural sample can provide self-shielding information about the isotope of interest, because the known isotopes contribute a predictable background that modulates the mixture's correction factor. In practice, this means that an evaluation campaign can combine one enriched-sample measurement with one natural-sample measurement, rather than requiring two enriched samples. The natural sample is orders of magnitude cheaper to produce and is often already available at neutron facilities. This capability is demonstrated in the $^{90}$Zr and $^{91}$Zr evaluation presented in \autoref{chap:evaluation}, where natural zirconium transmission data supplements the enriched datasets.

Implementing this capability, however, required overcoming the architectural rigidity of the legacy FORTRAN codebases of SESH and SAMMY\cite{sammy}. The original source code relied on static arrays and common blocks that could not dynamically accommodate a variable number of isotopes\cite{Wiarda2023SAMMY}. Extending the self-shielding routines to multi-isotope systems therefore required a piece-by-piece rewrite of the core routines, the scope and consequences of which are discussed in \autoref{sec:code-refactoring}.

\section{Framework for Multi-Isotope Self-Shielding}
\label{sec:multi-iso-framework}

For a sample composed of a mixture of isotopes, the average total microscopic cross section is a linear combination of the contributions from each constituent isotope, weighted by their respective atom fractions $\gamma_j$:
\begin{equation}
\langle \sigma \rangle_{\text{mix}} = \sum_j \gamma_j \frac{1}{N} \sum_{i} \sigma_{i,j}
\end{equation}
However, the nonlinear nature of the transmission complicates the self-shielding calculation. The average transmission of the mixture is:
\begin{equation}
\langle T \rangle_{\text{mix}} = \frac{1}{N} \sum_{i} \exp{\left(-n \sum_j \gamma_j \sigma_{ij}\right)}
\end{equation}
where $n$ is the total sample thickness in atoms per barn and the sum over $j$ runs over all isotopes in the mixture.

Because the exponential acts on the \textit{sum} of the isotopic cross sections, the self-shielding of the mixture cannot in general be decomposed into independent, isotope-by-isotope corrections. For transmission, a partial decomposition is possible in principle, but the approach is cumbersome and does not generalize to other observables such as capture yield, where the reaction cross section of the isotope of interest is entangled with the total cross section of the mixture in the flux depression. The multi-isotope framework adopted here treats the mixture jointly from the outset, avoiding these limitations\cite{wpec-15}.

One consequence of this coupling is that the presence of additional isotopes tends to dampen the self-shielding effect relative to a pure sample of a single isotope. The mechanism can be understood through the Porter-Thomas distribution\cite{Porter1956} that governs the sampled resonance widths. The Porter-Thomas distribution is strongly right-skewed: most sampled widths are small, but the occasional large width produces a resonance that dominates the local cross section. It is these rare, large resonances that drive the variance of the cross-section distribution and, through the $C_T \approx 1 + \frac{1}{2}n^2\mathrm{Var}(\sigma)$ relationship, the self-shielding correction. In a mixture, the contribution of each isotope's cross section to the total is weighted by its atom fraction $\gamma_j$. This weighting effectively scales down the apparent size of every resonance --- including the rare large ones that dominate the variance --- by the factor $\gamma_j$. The result is a reduction in the effective variance of the total cross section and a corresponding dampening of the self-shielding correction relative to what a pure sample of any single isotope would produce.

This dampening was confirmed by computing the transmission correction factor for a series of $^{90}$Zr/$^{92}$Zr mixtures at varying enrichments using MCNP, as shown in \autoref{fig:transmission-dampening}. At zero $^{90}$Zr enrichment, the sample consists entirely of $^{92}$Zr, and the correction factor reflects $^{92}$Zr's resonance structure alone. As $^{90}$Zr is introduced, the correction factor initially \textit{decreases}, because the large $^{92}$Zr resonances are diluted by the $^{90}$Zr background faster than $^{90}$Zr's own resonances build up. Beyond a minimum, the $^{90}$Zr resonance fluctuations begin to dominate the mixture's variance, and the correction factor increases monotonically with further enrichment.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{Multi Isotope/Figures/multiiso_v5.pdf}
    \caption{Transmission correction factor for a 3~cm sample of $^{90}$Zr/$^{92}$Zr as a function of $^{90}$Zr enrichment, computed with MCNP. The correction factor first decreases as $^{92}$Zr resonances are diluted, reaches a minimum, and then increases as $^{90}$Zr resonance fluctuations begin to dominate the mixture's variance.}
    \label{fig:transmission-dampening}
\end{figure}

\section{Validation Methodology}
\label{sec:multi-iso-validation}

The validation of the multi-isotope model followed the same fundamental strategy as the mono-isotopic case: a direct comparison of SAMMY's calculated correction factor against a high-fidelity MCNP simulation. Natural zirconium was chosen as the test system because its isotopic composition includes several isotopes with significant abundances and overlapping unresolved resonance regions, making it a demanding and representative test case.

A significant obstacle was discovered when using the standard ENDF/B-VIII.1 evaluations for the zirconium isotopes. In the ENDF format, data is organized into numbered ``Files'' by quantity type; of relevance here are File~2, which contains average resonance parameters, and File~3, which contains tabulated pointwise cross sections\cite{endf-manual}. In the URR, File~2 provides the statistical properties of resonances (average widths, level spacings, and strength functions) from which a code like SAMMY can reconstruct the expected average cross section and its fluctuations. Separately, File~3 provides a smooth pointwise cross section that is intended to represent the infinitely-dilute average.

For many evaluations, the File~3 cross section is not derived from the File~2 parameters but is instead based on independent sources. In the case of the current zirconium evaluations, the File~3 data is based directly on measured natural cross-section data\cite{Smith1979ZrHf}, which need not be consistent with the statistical model encoded in File~2. This inconsistency is a critical issue for validation: SAMMY calculates self-shielding from the File~2 resonance parameter distributions, while MCNP's probability table treatment is normalized against the File~3 pointwise cross section. A comparison between the two would conflate differences in the underlying cross-section inputs with differences in the self-shielding methodology, making it impossible to isolate the quantity under test.

To create a controlled comparison, a set of ``quasi-Zr'' ENDF files was generated. In this procedure, the File~2 average resonance parameters from the SAMMY input were used to compute a new, perfectly consistent File~3 via the Hauser-Feshbach formalism. This ensured that both SAMMY and the MCNP/NJOY toolchain started from the exact same physical model, isolating the self-shielding calculation as the only variable under scrutiny. The workflow is illustrated in \autoref{fig:validation-flowchart}, and the resulting comparison between the original ENDF/B-VIII.1 File~3 and the recalculated File~3 for $^{90}$Zr is shown in \autoref{fig:quasi-zr-comparison}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\linewidth]{Multi Isotope/Figures/Multi_Validation_Flowchart.pdf}
    \caption{Workflow for generating internally consistent ``quasi-Zr'' ENDF files. The File~2 average resonance parameters serve as the single source of truth, from which both the SAMMY input and a new, consistent File~3 are derived. This ensures that the subsequent MCNP benchmark comparison isolates the self-shielding methodology.}
    \label{fig:validation-flowchart}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{Multi Isotope/Figures/quasi-zr-totxs.pdf}
    \caption{Comparison of the original ENDF/B-VIII.1 File~3 total cross section for $^{90}$Zr (dashed) with the recalculated File~3 derived from the File~2 average resonance parameters (solid). The two differ because the original File~3 was based on measured natural cross-section data rather than on the statistical model in File~2.}
    \label{fig:quasi-zr-comparison}
\end{figure}

\section{Comparison with MCNP and the Probability Table Variance Issue}
\label{sec:multi-iso-discrepancy}

With a consistent set of ENDF files established, the multi-isotope self-shielding correction in SAMMY was benchmarked against MCNP. The results revealed a significant and initially unexpected discrepancy. As shown in \autoref{fig:zr-discrepancy}, the SAMMY calculation consistently predicted a larger transmission correction factor than the MCNP reference for a 10~cm natural zirconium sample. This indicated that SAMMY was predicting stronger self-shielding than MCNP, despite both codes using identical average resonance parameters and identical smooth cross sections.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{Multi Isotope/Figures/zr-discrepancy.pdf}
    \caption{Initial comparison of the transmission correction factor for a 10~cm natural Zr sample, showing the systematic overestimation by SAMMY relative to the MCNP benchmark. Both calculations use the same quasi-Zr ENDF files with consistent File~2 and File~3 data.}
    \label{fig:zr-discrepancy}
\end{figure}

The discrepancy was traced not to the SAMMY self-shielding model but to an artifact in the way MCNP applies probability tables in the URR. The following subsections describe the probability table methodology, identify the specific mechanism by which it distorts the cross-section variance, and confirm through a controlled numerical experiment that this variance distortion is the sole source of the observed disagreement.

\subsection{Probability Table Background}

Transport codes such as MCNP do not use the smooth File~3 cross section directly in the URR, because doing so would fail to capture the self-shielding effects caused by resonance fluctuations. Instead, they rely on probability tables to statistically represent the cross-section distribution within each energy group\cite{Levitt1972Probability, Carter1998MCNP}.

The generation of a probability table begins with the same statistical parameters from ENDF File~2 that SAMMY uses. A processing code such as NJOY generates many realizations of the resonance structure and computes the corresponding fluctuating cross sections. The resulting population of cross-section values is sorted by magnitude and divided into $J$ discrete bins. For each bin $j$, a representative cross section $\sigma_j$ is computed as the average of all samples within that bin, and the probability $P_j$ is the fraction of total samples falling within it:
\begin{equation}
    P_j = \frac{\text{Number of samples in bin } j}{N}, \qquad \sum_{j=1}^{J} P_j = 1.
\end{equation}
The sampled distribution has a mean $\mu = \sum_j P_j \sigma_j$ and a variance $V = \sum_j P_j (\sigma_j - \mu)^2$, both of which are determined by the underlying resonance parameter distributions and are physically meaningful quantities.

\subsection{Variance Scaling Under Mean Enforcement}
\label{ssec:variance-scaling}

In practice, the sampled mean $\mu$ from the probability table generation does not exactly equal the evaluator's target mean cross section $\langle \sigma \rangle$ provided in File~3. Differences arise from the use of different formalisms (e.g., SLBW in the probability table generation versus the evaluation's own cross-section model), finite sampling statistics, and processing approximations\cite{Cullen2010_ENDF369_URRHistory, Sublet2009_CEAR6227_URRPT_SelfShield}. To enforce consistency with the evaluator's mean, the standard approach (indicated by the \texttt{LSSF=1} flag in the ENDF-6 format\cite{endf-manual}) stores the probability table as dimensionless factors:
\begin{equation}
    f_j = \frac{\sigma_j}{\mu}
    \label{eq:ptable-factor}
\end{equation}
so that $\sum_j P_j f_j = 1$. During transport, the cross section is reconstructed by scaling these factors by the File~3 value:
\begin{equation}
    \sigma_j^{(\times)} = f_j \, \langle \sigma \rangle
    \label{eq:lssf-reconstruction}
\end{equation}
which guarantees that the reconstructed distribution has the correct mean, $\sum_j P_j \sigma_j^{(\times)} = \langle \sigma \rangle$.

However, this multiplicative rescaling applies uniformly to the entire distribution. Substituting \autoref{eq:ptable-factor} into \autoref{eq:lssf-reconstruction} reveals that each cross-section value is simply scaled by the ratio $\langle \sigma \rangle / \mu$:
\begin{equation}
    \sigma_j^{(\times)} = \frac{\langle \sigma \rangle}{\mu} \, \sigma_j.
\end{equation}
Because the variance of a linearly scaled random variable satisfies $\mathrm{Var}(aX) = a^2 \mathrm{Var}(X)$, the variance of the reconstructed distribution becomes:
\begin{equation}
    \mathrm{Var}\!\left(\sigma^{(\times)}\right) = \left(\frac{\langle \sigma \rangle}{\mu}\right)^2 V.
    \label{eq:variance-scaling}
\end{equation}
Whenever the sampled mean $\mu$ and the evaluator mean $\langle \sigma \rangle$ differ, the variance used in transport is systematically distorted. If $\langle \sigma \rangle > \mu$, the variance is inflated; if $\langle \sigma \rangle < \mu$, it is suppressed.

This is physically incorrect. As established in the Kawai-Kerman-McVoy (KKM) decomposition of the scattering matrix\cite{Kawai1973}, the cross section separates into an optical (smooth) component and a fluctuation component, and the within-bin variance depends only on the fluctuation component. The variance is therefore a property of the compound-nucleus statistical model encoded in the File~2 parameters and is independent of the smooth mean cross section. Scaling the variance with the mean conflates two physically independent quantities.

The practical consequence follows directly from the connection between variance and self-shielding derived in \autoref{sec:resonance-self-shielding}. Recalling the first-order Taylor Series expansion, the transmission correction factor is approximately $C_T \approx 1 + \frac{1}{2} n^2 \mathrm{Var}(\sigma)$. A probability table whose variance has been suppressed by the factor $(\langle \sigma \rangle / \mu)^2$ will systematically underpredict the correction factor, and the underprediction will grow with sample thickness as the transmission becomes more sensitive to the tails of the distribution. This is precisely the pattern observed in \autoref{fig:zr-discrepancy} and in the mono-isotopic thickness study in \autoref{chap:transmission-correction}: SAMMY, which samples directly from the resonance parameter distributions without any intermediate normalization, consistently predicts a larger correction than the MCNP benchmark whose probability tables have undergone this multiplicative mean enforcement.

The effect of this normalization on the sampled cross-section distribution is illustrated in \autoref{fig:zr-ptable-scaling} for $^{90}$Zr at 200~keV, where the File~3 cross section differs from the sampled mean. The entire distribution is shifted and compressed by the multiplicative factor, altering both the mean and the variance simultaneously.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\linewidth]{Multi Isotope/Figures/zr90-ptables.pdf}
    \caption{Sampled cross-section distribution for $^{90}$Zr at 200~keV before and after \texttt{LSSF=1} normalization. The multiplicative rescaling $\sigma_j^{(\times)} = f_j \langle \sigma \rangle$ enforces the File~3 mean but simultaneously distorts the variance of the distribution by the factor $(\langle \sigma \rangle / \mu)^2$.}
    \label{fig:zr-ptable-scaling}
\end{figure}

\subsection{Isolating the Variance Distortion}
\label{ssec:isolating-variance}

To confirm that the probability table variance distortion was the sole source of the SAMMY--MCNP discrepancy, a controlled numerical experiment was performed. The cross-section sampling routines from SAMMY and NJOY were decoupled from their respective transmission calculation methods, yielding four possible combinations: SAMMY-sampled cross sections with direct averaging, SAMMY-sampled cross sections processed through probability tables, NJOY-sampled cross sections with direct averaging, and NJOY-sampled cross sections processed through probability tables.

The results, shown in \autoref{fig:variance-comparison}, are unambiguous. When the same transmission calculation method is used, the SAMMY-sampled and NJOY-sampled cross sections produce identical correction factors, confirming that the two codes sample statistically equivalent resonance ladders from the same File~2 parameters. The discrepancy appears only when comparing the direct averaging method to the probability table method, regardless of which code generated the underlying cross-section samples. Furthermore, when SAMMY's direct sampling is deliberately degraded to reproduce the variance-scaled distribution implied by \autoref{eq:variance-scaling}, the resulting correction factor matches the MCNP probability table result exactly.

This establishes two conclusions. First, the SAMMY multi-isotope self-shielding model is correct: it faithfully computes the correction factor from the physically sampled cross-section distribution. Second, the observed discrepancy with MCNP is entirely attributable to the variance distortion introduced by the \texttt{LSSF=1} mean-enforcement procedure in the probability table workflow. MCNP does not disagree with SAMMY because SAMMY overestimates the self-shielding; rather, MCNP underestimates it because the probability table normalization has suppressed the cross-section variance below its physically sampled value.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{Multi Isotope/Figures/variance-comparison-2.pdf}
    \caption{Transmission correction factor for a 5.15~cm $^{90}$Zr sample computed using four combinations of sampling source (SAMMY vs.\ NJOY) and transmission calculation method (direct averaging vs.\ probability tables). The two sampling sources agree when the same calculation method is used; the discrepancy arises solely from the probability table normalization.}
    \label{fig:variance-comparison}
\end{figure}

A detailed analysis of the probability table variance issue, including a variance-preserving correction methodology and its validation against both controlled transmission tests and integral criticality benchmarks, is the subject of a companion publication\cite{Golas2025VariancePreservation}.


\section{Verification of the Integrated Fitting Procedure}
\label{sec:multi-iso-fitting}

With the multi-isotope self-shielding model validated, the next step was to verify the integrated fitting procedure end-to-end. This verification follows the same strategy as the mono-isotopic case in \autoref{chap:transmission-correction}: demonstrating that the SAMMY fitting engine can recover known resonance parameters from synthetic data.

The legacy SAMMY URR workflow was already capable of fitting multiple datasets simultaneously, but only datasets of the same type --- specifically, average cross-section measurements at different energies or for different isotopes. The modernization described in \autoref{sec:code-refactoring} extends this to datasets of fundamentally different types: average cross sections, self-shielded transmissions, and capture yields can now be included in a single simultaneous fit. This is not merely a convenience; it addresses a physical limitation of cross-section-only fitting.

Average cross-section data constrains the mean value of the cross section but carries no information about its fluctuation distribution. As a result, parameters that affect the mean in compensating ways --- notably the strength functions $S_\ell$ and the distant-level parameter $R^\infty_\ell$ --- are strongly anti-correlated: an increase in $S_\ell$ can be offset by a decrease in $R^\infty_\ell$ (or vice versa) to produce nearly the same average cross section. This degeneracy can be partially broken by fitting over a wide energy range, since the two parameters have different energy dependences, but over narrow ranges the trade-off is nearly exact. Self-shielded transmission data, by contrast, depends nonlinearly on the cross-section distribution through the correction factor $C_T$, which is sensitive to the variance and higher moments of the distribution. Including a transmission dataset alongside a cross-section dataset therefore provides an independent constraint that breaks the $S_\ell$--$R^\infty_\ell$ degeneracy: the cross section pins the mean, while the transmission pins the fluctuation content.

To validate this capability, two synthetic datasets were generated for natural zirconium using the quasi-Zr ENDF files: a self-shielded transmission measurement for a 4~cm thick sample and an average total cross-section measurement. The $^{90}$Zr strength functions ($S_0$, $S_1$, $S_2$) were the fitted parameters, while all other isotopic parameters were held at their known values. The starting parameters were deliberately offset from the truth values by factors of two or more to ensure that the fit must traverse a substantial region of parameter space.

The fitted curves are compared against the synthetic data in \autoref{fig:multi-isotope-fitting-validation}. Starting from a dramatically incorrect initial prediction ($\chi^2/N = 7598$), the simultaneous fit converges to a final $\chi^2/N = 0.697$, reproducing both synthetic datasets. The recovered $^{90}$Zr strength functions, listed in \autoref{tab:multi-isotope-fitting-results}, agree with the truth values to within 1\% for all three partial waves. The recovery of $S_0$ from 0.24 to 0.545 (target 0.54) and $S_1$ from 1.8 to 3.800 (target 3.8) is particularly notable, as these parameters were initialized at less than half their true values. This level of recovery from such large initial offsets confirms that the fitting landscape is well-behaved and that the simultaneous multi-dataset approach provides sufficient constraint to determine all three strength functions unambiguously.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{Multi Isotope/Figures/multi-isotope-fit.pdf}
    \caption{Simultaneous fit to synthetic natural Zr data: average total cross section and 4~cm self-shielded transmission. The solid curves show the converged fit; the prior (starting from deliberately incorrect parameters) is shown for comparison. The fit recovers both datasets from an initial $\chi^2/N$ of 7598 to a final value of 0.697.}
    \label{fig:multi-isotope-fitting-validation}
\end{figure}

\begin{table}[H]
    \centering
    \caption{Recovery of $^{90}$Zr neutron strength functions ($\times 10^{-4}$) from a simultaneous fit to synthetic natural Zr transmission and total cross-section data. The prior values were deliberately offset from the target to test convergence from a poor initial guess.}
    \begin{tabular}{|c|ccc|}
        \hline
        Parameter & Target & Prior & Final Fit \\
        \hline
        $S_0$   & 0.54  & 0.24 & 0.545 \\
        $S_1$   & 3.8   & 1.8  & 3.7995 \\
        $S_2$   & 1.5   & 0.5  & 1.496 \\
        \hline
        $\chi^2/N$ & -- & 7597.55 & 0.697 \\
        \hline
    \end{tabular}
    \label{tab:multi-isotope-fitting-results}
\end{table}


\section{Additional Capabilities from the Code Modernization}
\label{sec:code-refactoring}

A substantial portion of the effort in developing the multi-isotope capability was dedicated to refactoring the underlying SAMMY codebase. The original URR routines were characterized by a tangled dependency structure, shown in \autoref{fig:old-codemap}, in which data flow between subroutines was mediated by shared FORTRAN common blocks and hard-coded array dimensions. This architecture could not accommodate a variable number of isotopes and made it difficult to modify any single routine without risking unintended side effects elsewhere.

The codebase was reorganized into modular components with well-defined interfaces, producing the hierarchical architecture shown in \autoref{fig:new-codemap}. This restructuring was a prerequisite for the multi-isotope extension, but it also enabled several capabilities that extend well beyond the original goal.

The refactored code accepts resonance parameters in JSON format, replacing the rigid fixed-column input files inherited from the legacy SAMMY workflow. More significantly, the modular design supports the definition of energy-dependent resonance parameters --- quantities defined on a user-specified energy grid and interpolated to the calculation energies during the fit. In the legacy workflow, introducing energy dependence required partitioning the URR into independent energy bins, each with its own set of parameters. This approach decorrelates the parameters across bins, preventing the fitter from enforcing any physical continuity between adjacent energy regions. The new interpolated-grid approach treats the energy-dependent parameter as a single, continuous object whose values at the grid nodes are the fitted quantities; the interpolation enforces smoothness automatically. This capability was developed specifically to enable the doorway-state parameterization of the $s$-wave strength function in $^{90}$Zr, where the strength function varies with energy in a manner that does not follow the slowly varying predictions of compound-nucleus statistics and is a central topic of the evaluation presented in \autoref{chap:evaluation}. However, the mechanism is general and can be applied to any parameter for which energy dependence is physically motivated.

A further consequence of the refactoring is that the URR fitting routines now share infrastructure with the resolved resonance region (RRR) fitter through the common \texttt{fitAPI} interface. In the legacy codebase, the RRR and URR fitting engines were so architecturally separate that they were effectively independent programs. The unified interface makes it straightforward to perform simultaneous fits that correlate RRR and URR parameters --- for example, constraining the transition between the two regions or sharing common quantities such as the distant-level parameter.

The new framework also propagates uncertainties from experimental conditions --- sample thickness, isotopic composition, and temperature --- into the final fitted parameter covariance matrix through the procedures described in \autoref{chap:uncertainty}. This produces more realistic uncertainty estimates than the legacy approach, which treated these quantities as exactly known. Finally, integration with the \texttt{fitAPI} provides access to modern fitting algorithms, including the gradient descent method described in \autoref{app:gradient-descent}, which supplements the Bayesian update used in the legacy code and enables more robust convergence for problems with many parameters or poor initial guesses.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.35\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Multi Isotope/Figures/OriginalCode.pdf}
        \caption{Original URR code architecture, characterized by tangled dependencies and shared global state.}
        \label{fig:old-codemap}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.55\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Multi Isotope/Figures/RefactoredCode.pdf}
        \caption{Refactored architecture with modular components and well-defined interfaces, integrated into the \texttt{fitAPI} framework.}
        \label{fig:new-codemap}
    \end{subfigure}
    \caption{Comparison of the URR codebase architecture before and after the refactoring effort. The original structure (a) could not accommodate a variable number of isotopes; the modular design (b) supports multi-isotope calculations and integration with modern fitting infrastructure.}
    \label{fig:code-refactoring}
\end{figure}

\section{Summary}
\label{sec:multi-iso-summary}

This chapter has presented the extension of the SAMMY self-shielding correction to multi-isotope systems, a capability that fundamentally changes the experimental requirements for URR parameter evaluation by enabling the use of natural-element samples alongside enriched samples. The theoretical framework accounts for the inter-isotope dampening of self-shielding that arises from the nonlinear dependence of transmission on the mixture's total cross section.

Validation against MCNP required the construction of internally consistent ``quasi-Zr'' ENDF files to eliminate spurious differences between File~2 and File~3 data. The subsequent benchmark comparison revealed a systematic discrepancy that was traced to the probability table methodology used by MCNP: the standard \texttt{LSSF=1} mean-enforcement procedure multiplicatively rescales the sampled cross-section distribution, which distorts the physically meaningful variance by the factor $(\langle \sigma \rangle / \mu)^2$. A controlled numerical experiment confirmed that SAMMY's resonance ladder sampling agrees with NJOY's when the same transmission calculation method is applied, and that deliberately introducing the same variance distortion into SAMMY's calculation reproduces the MCNP result exactly. The discrepancy therefore lies in the probability table normalization and not in the SAMMY self-shielding model.

With the physics model validated, the integrated multi-isotope fitting workflow was verified by recovering known $^{90}$Zr strength functions from synthetic natural zirconium data through simultaneous fitting of transmission and total cross-section datasets. The recovered parameters agree with the truth values to within 1\%, confirming the correctness of both the multi-isotope self-shielding correction and the modernized fitting infrastructure. This capability is applied to a real evaluation in \autoref{chap:evaluation}.
